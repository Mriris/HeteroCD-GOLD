# 主要符号表

| 符号 | 描述 |
|------|------|
| $I_1, I_2$ | 输入的两个时相遥感图像 |
| $\text{Encoder}_1, \text{Encoder}_2$ | 两个独立的特征提取编码器 |
| $F_1, F_2$ | 提取的特征集合 |
| $F_i^j$ | 第$i$个时相图像的第$j$层特征 |
| $F_i^{fused}$ | 时相$i$的融合特征 |
| $F_{cat}, F_{diff}$ | 特征拼接结果；经过卷积提取的差异特征 |
| $\hat{M}$ | 最终的变化检测输出图 |
| $\mathcal{L}_{CE}, \mathcal{L}_{Dice}, \mathcal{L}_{total}$ | 交叉熵损失函数；Dice损失函数；总损失函数 |
| $\mathcal{L}_{CD}, \mathcal{L}_{D}, \mathcal{L}_{A}$ | 变化检测损失；知识蒸馏损失；差异图注意力损失 |
| $\mathcal{L}_{T}, \mathcal{L}_{DW}$ | 教师网络损失；动态权重损失 |
| $\mathcal{L}_{feat}, \mathcal{L}_{out}$ | 特征级损失；输出级损失 |
| $\mathcal{L}_{att\_D}$ | 差异图注意力损失 |
| $\mathcal{L}_{map}, \mathcal{L}_{sp}, \mathcal{L}_{ch}$ | 差异图损失；空间注意力损失；通道注意力损失 |
| $\mathcal{L}_{c}, \mathcal{L}_{nc}$ | 变化区域特征迁移损失；非变化区域特征迁移损失 |
| $\mathcal{L}_{f}, \mathcal{L}_{a}, \mathcal{L}_{d}$ | 特征级损失(综合)；注意力机制损失(综合)；差异图损失(综合) |
| $D_{L2}, D_{cos}, D_{comb}, D_{map}$ | 欧氏距离差异图；余弦相似度差异图；组合差异图；最终差异图 |
| $D_o, D_n, D_e$ | 原始差异图；归一化差异图；自适应增强后的差异图 |
| $D_s, D_t$ | 学生网络差异图；教师网络差异图 |
| $A_{ch}, A_{sp}$ | 通道注意力；空间注意力 |
| $A_{sp}^t, A_{ch}^t, A_{sp}^s, A_{ch}^s$ | 教师网络的空间/通道注意力；学生网络的空间/通道注意力 |
| $W_1, W_2, W_s$ | 通道注意力权重 |
| $S_s, S_t$ | 学生网络和教师网络的软化输出 |
| $T$ | 温度参数(蒸馏中用于软化输出分布) |
| $r_c, w_{cd}$ | 变化区域的比例；变化检测损失的权重 |
| $\theta, M_w$ | 自适应阈值；权重掩码 |
| $R_c, R_{nc}$ | 变化区域和非变化区域的二值掩码 |
| $\epsilon$ | 小常数(用于防止除零和数值稳定) |

第2章 相关理论基础
2.1.孪生全卷积神经网络
本研究选用的基线模型采用孪生全卷积神经网络结构接收两个时相的遥感图像，使用基于交叉熵损失和Dice损失的组合损失函数，通过监督学习方式直接建立输入图像与变化标签之间的映射关系，最终输出黑白二值变化图。
2.1.1.编码器与特征提取
基线模型的核心是两个独立的ResNet-18网络，通过专门的特征提取网络处理两个时相的图像，能够有效提取各自特有的特征信息。两个时相图像的特征提取过程及其多尺度特征集合可表示为：
	\[\begin{align}
  & {{F}_{1}}=\text{Encode}{{\text{r}}_{1}}({{I}_{1}}){{F}_{2}}=\text{Encode}{{\text{r}}_{2}}({{I}_{2}}) \\ 
 & {{F}_{i}}=\{F_{i}^{1},F_{i}^{2},F_{i}^{3},F_{i}^{4}\},\quad i\in \{1,2\} \\ 
\end{align}\]	
其中，${{I}_{1}}$和${{I}_{2}}$分别表示输入的两个时相遥感图像，$\text{Encode}{{\text{r}}_{1}}$和$\text{Encode}{{\text{r}}_{2}}$表示两个独立的特征提取编码器，${{F}_{1}}$和${{F}_{2}}$是提取的特征集合，$F_{i}^{j}$表示第$i$个时相图像的第$j$层特征，其中$j=1$表示浅层特征（分辨率最高），$j=4$表示深层特征（语义信息最丰富）。编码器的基本构建模块是残差块，通过跳跃连接机制有效缓解了深层网络中的梯度消失问题。残差块的设计思想是让网络学习输入与输出之间的残差映射，使深层网络的训练更加稳定，而不是直接学习复杂的非线性映射。基线模型的残差块计算表示如下：
	\[\mathbf{y}=\mathcal{F}(\mathbf{x},\{{{W}_{i}}\})+\mathbf{x}\]	
其中，$\mathbf{x}$是输入特征，$\mathbf{y}$是输出特征，$\mathcal{F}$表示残差映射函数，$\{{{W}_{i}}\}$表示残差映射中的卷积权重参数。残差映射$\mathcal{F}$由卷积、批归一化（BN）与激活函数（ReLU）组成，这种设计使网络能够更容易地学习恒等映射。为了充分利用编码器提取的多尺度特征，基线模型在特征转换阶段采用了一系列操作来整合不同尺度的信息，首先对每个尺度的特征通过1×1卷积进行通道降维来降低计算复杂度并提取最关键的特征信息，然后将不同尺度的特征统一到相同的空间分辨率，最后对各尺度特征进行整合来生成单一的融合特征。这一系列特征转换过程可以表示为：
	\[\begin{align}
  & F_{i}^{{{j}'}}=\text{Conv1x1}(F_{i}^{j}),\quad F_{i}^{{{j}''}}=\text{Resize}(F_{i}^{{{j}'}},\text{size}=F_{i}^{1}.\text{shape}) \\ 
 & F_{i}^{fused}=\text{FusionCon}{{\text{v}}_{i}}([F_{i}^{{{1}''}},F_{i}^{{{2}''}},F_{i}^{{{3}''}},F_{i}^{{{4}''}}]),\quad i\in \{1,2\} \\ 
\end{align}\]	
其中，$F_{i}^{{{j}'}}$表示经过1×1卷积降维后的特征，$\text{Conv1x1}$表示1×1卷积操作，$\text{Resize}$表示改变特征图空间尺寸的操作，将所有特征调整到与第一层特征（$F_{i}^{1}$）相同的空间分辨率，$[...]$表示在通道维度上的特征拼接操作，$\text{FusionCon}{{\text{v}}_{i}}$表示用于融合多尺度特征的卷积层，两个时相使用独立的融合卷积层，$F_{i}^{fused}$表示时相$i$的融合特征，包含了从浅层到深层的全部特征信息。
2.1.2.时相差异提取与变化检测
在获取两个时相的特征表示后，基线模型将两个时相的特征在通道维度上拼接，让后续的卷积层学习它们之间的差异关系：
	\[{{F}_{cat}}=[F_{1}^{fused},F_{2}^{fused}]\]	
其中的${{F}_{cat}}$表示特征拼接结果，通过将两个时相的特征在通道维度连接来保留完整的原始信息，以供后续层学习差异。这种方法相比于直接计算特征差值更加灵活，能够让网络自行学习最有效的差异提取方式。拼接后的特征经过一个简单的卷积层，将拼接特征转化为差异特征表示。随后通过Dropout层增强模型的泛化能力，使用一个1×1卷积层作为分割头部，输出每个像素的变化概率：
	\[\begin{align}
  & {{F}_{diff}}=\text{Conv}({{F}_{cat}}) \\ 
 & {{F}_{dropout}}=\text{Dropout}({{F}_{diff}},p=0.1) \\ 
 & \hat{M}=\text{ConvSeg}({{F}_{dropout}}) \\ 
\end{align}\]	
其中，${{F}_{diff}}$表示经过卷积提取的差异特征，${{F}_{dropout}}$表示应用了Dropout随机失活后的特征，$\text{ConvSeg}$表示最终的分割头部，$\hat{M}$表示最终的变化检测输出图。模型最终输出的是每个像素属于变化类别的概率图，在设定概率阈值后就可以得到变化区域的二值图了。
2.1.3.损失函数
遥感图像变化检测的任务类别不平衡现象较为严重，一般而言变化的区域只会占据整个遥感图像很小一部分。针对这种不平衡问题，在基线模型的训练过程中，采用组合损失函数。首要是带权重的交叉熵损失函数，即通过对不同的类别赋予不同的权值系数，使得变化与未变化区域对损失计算的影响更加均衡，保证模型能够充分注意到稀少变化的样本数据。该损失函数的数学表达式如下：
	\[{{\mathcal{L}}_{CE}}=-\frac{1}{N}\sum\limits_{i=1}^{N}{\sum\limits_{c=0}^{1}{{{w}_{c}}}}\cdot {{y}_{i,c}}\cdot \log ({{p}_{i,c}})\]	
其中，$N$表示图像中像素的总数，$c$表示类别索引，0表示未变化类别，1表示变化类别，${{w}_{c}}$是类别$c$的权重系数，为变化区域分配更高的权重以平衡类别不平衡，${{y}_{i,c}}$是像素$i$属于类别$c$的真实标签（0或1），${{p}_{i,c}}$是模型预测像素$i$属于类别$c$的概率。为了改善边界区域的检测效果，基线模型还引入了基于区域重叠度度量的Dice损失函数，对分割边界更为敏感，能够促使模型生成更精确的变化边界。Dice损失函数的计算公式如下：
	\[{{\mathcal{L}}_{Dice}}=1-\frac{1}{C}\sum\limits_{c=1}^{C}{\frac{2\cdot \sum\limits_{i}^{N}{{{p}_{i,c}}}\cdot {{y}_{i,c}}+\epsilon }{\sum\limits_{i}^{N}{{{p}_{i,c}}}+\sum\limits_{i}^{N}{{{y}_{i,c}}}+\epsilon }}\]	
其中，$C$表示类别数量，$\epsilon $是极小常数，用于防止分母为零和提高数值稳定性，分子表示预测结果和真实标签的交集，分母表示预测结果和真实标签的并集。Dice系数值越高代表预测结果与真实标签重叠度越高，所以损失函数取为1减去平均Dice系数。基线模型将交叉熵损失和Dice损失加权组合作为总损失函数，能够同时关注像素级的分类准度和区域级的分割质量，促使模型在训练过程中同时关注变化区域和非变化区域，提高对变化边界的敏感度，从而在变化检测任务中取得良好的性能。最终损失函数是两者加和：
	\[{{\mathcal{L}}_{total}}={{\mathcal{L}}_{CE}}+{{\mathcal{L}}_{Dice}}\]	
2.2.在线蒸馏
知识蒸馏（Knowledge Distillation）最初由Hinton等人在2015年中提出，其核心思想是将大型复杂模型（教师模型）的"知识"转移到小型简单模型（学生模型）中[32]。但是传统知识蒸馏存在预先训练教师模型、两阶段训练流程等局限性，导致准备时间太久且对教师模型的选择依赖经验。面对这些局限性，Guo等人提出了在线蒸馏（Online Knowledge Distillation）的概念，打破了传统蒸馏中教师-学生的固定角色设定，实现了单阶段、无需预训练教师模型的知识蒸馏过程[33]。
在线蒸馏的核心是协作学习机制，能够让多个网络模型在训练过程中相互学习，共同提升。与传统的教师-学生蒸馏范式不同，在线蒸馏中的网络可以同时扮演教师和学生的角色，通过相互协作和知识交换实现了协同提升。在线蒸馏的本质其实就是多个模型同时训练，并在训练过程中相互提供软目标（soft targets）作为额外的监督信号，从而实现知识的相互迁移和提炼。软目标是知识蒸馏中至关重要的概念，是经过softmax函数处理后得到的概率分布，包含了模型对各个类别的相对置信度信息。在线蒸馏的软目标生成是即时的，可以通过多模型输出的动态集成和关注模型间多样性的差异特征来实现，并通过KL散度等相似度度量方式，指导模型的训练过程。温度系数是控制软目标"软化"程度的重要超参数，当温度系数较大时，概率分布会变得更加平滑，类别间的差异随之更小，能够使模型之间更有效地共享"暗知识"（正确类别以外的预测概率）。
在线蒸馏具有许多显著优势：通过知识迁移减轻不同数据间的域差异，使模型能够更好地处理异质数据；无需预先训练教师模型，提高训练效率；网络间相互引导学习更好的特征表示，克服数据表示障碍；通过知识迁移，增强模型的泛化能力。
2.3.差异图注意力迁移机制
差异图注意力迁移机制起源于基于注意力的变化检测研究。Wang等人提出了基于注意力机制的变化检测方法，Li等人进一步扩展了注意力迁移的概念，证明了注意力图迁移在视觉任务中的显著有效性[34,35]。差异图注意力迁移的核心思想是通过模拟人类视觉系统对变化区域的关注能力，将一种数据识别的变化区域注意力模式迁移到另一种数据的处理过程中。这种迁移不直接作用于原始图像或特征，而是通过差异图和注意力机制的结合实现的。
差异图是指通过计算两个特征图之间的差异得到的显著性图，可以使用多种度量方式：
	\[\begin{align}
  & {{D}_{comb}}=\frac{{{D}_{L2}}+{{D}_{cos}}}{2} \\ 
 & {{D}_{L2}}=\sqrt{\sum{{{({{F}_{1}}-{{F}_{2}})}^{2}}}+\varepsilon } \\ 
 & {{D}_{cos}}=1-\frac{{{F}_{1}}\cdot {{F}_{2}}}{\|{{F}_{1}}\|\cdot \|{{F}_{2}}\|} \\ 
\end{align}\]	
其中，\[{{D}_{L2}}\]为欧氏距离差异图，${{D}_{cos}}$为余弦相似度差异图。${{F}_{1}}$和${{F}_{2}}$分别代表两个特征图，$\varepsilon $是小常数防止除零错误。注意力机制包括两个主要组件：通道注意力（Channel Attention）关注"什么变化了"，捕获不同通道（特征）的重要性；空间注意力（Spatial Attention）关注"哪里变化了"，突出特征图上的重要区域。
	\[\begin{align}
  & {{A}_{ch}}=\sigma (MLP(GlobalAvgPool(F))+MLP(GlobalMaxPool(F))) \\ 
 & {{A}_{sp}}=\sigma (Conv([AvgPoo{{l}_{c}}(F);MaxPoo{{l}_{c}}(F)])) \\ 
\end{align}\]	
其中，$\sigma $是\[sigmoid\]激活函数，$MLP$是多层感知机，$AvgPoo{{l}_{c}}$和$MaxPoo{{l}_{c}}$表示沿通道维度的平均池化和最大池化。


第3章 模型设计与实现

图 3.1 GOLD模型整体框架
GOLD模型打破了传统双分支结构的束缚，创新性地构建了三分支架构来解决异源遥感变化检测问题，引入的第三分支重构了变化检测思路，将变化检测任务分解为两个子网络：学生网络负责处理光学-SAR异源检测任务，由事前的光学分支和事后的SAR分支组成；教师网络专注于光学-光学同源检测，由事前和事后的光学分支构成。这种师生架构设计突破了传统方法仅依赖异源数据的局限，使模型能够从相对容易的同源变化检测中获取变化模式知识，指导更具挑战性的异源检测任务。
3.1.编码器改进：双向通道注意力
异源数据的特征差异一直是变化检测中的主要难题。本文的GOLD模型各分支采用ResNet18作为骨干网络提取多尺度特征，这些特征经过卷积层进行通道统一与初步融合，不过并未停留于简单的特征拼接，而是深入探索了模态间的交互机制，使不同模态特征能够相互增强，共同提升变化感知能力。本文引入了创新的双向通道注意力机制，分别计算两个分支特征的通道注意力权重，并交换应用这些权重来增强对方特征，允许一个模态指导另一个模态的特征提取，从而缓解异源数据的模态差异。本文还引入了共享注意力权重来增强双方特征，使用残差连接保留原始信息，确保信息传递的完整性。
对于两个模态的特征${{F}_{1}}$和${{F}_{2}}$，改进的编码器首先计算各自的通道注意力权重${{W}_{1}}$和${{W}_{2}}$，然后将这些权重交叉应用，同时加入共享权重${{W}_{s}}$的影响，保留原始特征以防信息丢失：
	\[\begin{align}
  & {{F}_{{{1}'}}}=({{F}_{1}}\cdot {{W}_{2}})+({{F}_{1}}\cdot {{W}_{s}})+{{F}_{1}} \\ 
 & {{F}_{{{2}'}}}=({{F}_{2}}\cdot {{W}_{1}})+({{F}_{2}}\cdot {{W}_{s}})+{{F}_{2}} \\ 
\end{align}\]	
这里增强后的特征${{F}_{{{1}'}}}$和${{F}_{{{2}'}}}$由三部分组成：一部分是由另一模态的权重${{W}_{2}}$或${{W}_{1}}$调制的特征，代表跨模态的信息交互，一部分是由共享权重${{W}_{s}}$调制的特征，代表两模态的共同关注点，还有一部分是保留的原始特征，确保重要信息不会因为权重调整而丢失。这些通道注意力权重如何计算呢？本文结合了平均池化和最大池化两种策略，以捕捉特征的不同统计属性：
	\[\begin{align}
  & {{W}_{1}}=\sigma (MLP(AvgPool({{F}_{1}}))+MLP(MaxPool({{F}_{1}}))) \\ 
 & {{W}_{2}}=\sigma (MLP(AvgPool({{F}_{2}}))+MLP(MaxPool({{F}_{2}}))) \\ 
 & {{W}_{s}}=\sigma (ML{{P}_{s}}([Poo{{l}_{avg}}({{F}_{1}},{{F}_{2}})]+[Poo{{l}_{max}}({{F}_{1}},{{F}_{2}})])) \\ 
\end{align}\]	
其中$AvgPool$和$MaxPool$分别表示平均池化和最大池化，用于压缩特征的空间维度，提取通道级别的统计信息，$MLP$是多层感知机，用于学习通道间的关系，$\sigma $是sigmoid激活函数，将权重限制在0到1之间，便于后续的注意力机制，而$[\cdot ]$表示特征拼接操作，将不同来源的特征结合起来，用于计算共享权重。
经过这样一种精巧的双向交互，基线方法异源特征融合的难题能被有效解决。共享MLP可以提取模态间共有的模式，而专用MLP负责模态间的交互注意学习，最后通过残差连接保证其传递过程的完整性与稳定性，从而能够充分屏蔽传感器本身的不同所引入的噪声扰动，着重于真实建筑物的变化。
3.2.在线蒸馏：从同源到异源的知识桥梁
平常的直接监督学习方法难以应对异源数据的复杂性，而GOLD模型在三分支架构的基础上，通过在线蒸馏机制创新性地将教师-学生知识迁移范式引入变化检测领域，协同训练实现知识的实时传递，使模型从容易的同源任务中学习变化模式，再迁移到困难的异源任务中，根本性地开创了异源变化检测的学习范式。
3.2.1.三分支协同学习的工作机制
GOLD模型的三个分支通过协同工作机制实现知识的高效传递：事前的光学分支负责处理初始状态图像，提取出关键的特征表示，事后的SAR分支和光学分支分别处理后续状态的两种不同模态图像。它们提取的特征共同构成了GOLD模型的知识基础：学生网络负责处理异源变化检测任务，接收事前的光学特征和事后的SAR特征作为输入，通过双向通道注意力机制增强这些特征，然后将增强后的特征拼接生成差异图，计算相应的空间和通道注意力，最终通过特征融合输出变化预测结果；教师网络专注于同源变化检测任务，使用事前和事后的光学特征，经过相同的处理流程生成变化预测结果。
本文提出了一种新的协同学习机制，其创新之处在于引入了跨模态的知识迁移思想，打破了传统变化检测"闭门造车"式的思想定式：事前共享的光学支路可以保证两种知识的一致性，因此提供可靠的转移基础；在线学习机制使模型知识能实时更新，可以让模型更适应变化的环境；测试时仅需用到学生网络部分，不需要事后光学数据作为支撑，与常见的模型保持一致的输入。对于实际操作来说，光学图像是比较容易获取和理解的，而且SAR图像有全天候、全天时的特点，但是由于其成像机制，所以识别难度相对较高。GOLD模型就是充分运用了这一点，用简单易懂的光学-光学变化指导了不容易被识别的光学-SAR变化。
3.2.2.多任务学习与损失函数
GOLD模型利用多任务学习框架和复合损失函数同时优化指标，在总体损失函数上集成了各个部分的学习目标，形成一套全方位的目标优化方案：
	\[{{\mathcal{L}}_{total}}={{\mathcal{L}}_{CD}}+{{\mathcal{L}}_{D}}+{{\mathcal{L}}_{A}}+{{\mathcal{L}}_{T}}+{{\mathcal{L}}_{DW}}\]	
这个公式的每个组成部分都针对变化检测任务的特定问题：基础变化检测损失${{\mathcal{L}}_{CD}}$确保模型能够准确识别变化区域，结合了交叉熵（关注每个像素的分类准确性）和Dice系数（关注整体区域的分割质量）；知识蒸馏损失${{\mathcal{L}}_{D}}$搭建了从同源到异源的知识桥梁，引导学生网络向教师网络学习；差异图注意力损失${{\mathcal{L}}_{A}}$增强了模型对变化区域的感知能力；教师网络损失${{\mathcal{L}}_{T}}$确保教师网络本身的变化检测准确性；动态权重损失${{\mathcal{L}}_{DW}}$则平衡了不同学习目标，实现自适应优化。
本文提出的多任务学习框架通过动态权重机制实现了任务间的互补增强，考虑了各阶段的特性。训练初期模型更关注基础变化检测任务，而随着训练轮次的推进，知识蒸馏和注意力迁移任务的权重会逐渐增加，从而实现从基础到高级的平滑学习过渡。
3.2.3.深度异源注意力蒸馏
GOLD模型的注意力蒸馏是多层次、多角度的知识迁移过程，涵盖特征级、输出级和注意力级三个层面。为了全面传递知识，本文设计了多种损失函数来捕捉不同层次的信息。特征级损失结合了均方误差（MSE）和余弦相似度，同时关注特征向量的欧几里得距离和方向一致性：
	\[{{\mathcal{L}}_{feat}}=0.7\cdot MSE({{F}_{s}},{{F}_{t}})+0.3\cdot Cos({{F}_{s}},{{F}_{t}})\]	
这里的${{F}_{s}}$和${{F}_{t}}$分别是学生网络和教师网络的特征表示，权重系数代表着变化检测更看重特征值的接近程度，但也不忽视特征方向的相似性。输出级损失采用KL散度（Kullback-Leibler散度）度量学生网络和教师网络输出概率分布的差异：
	\[{{\mathcal{L}}_{out}}={{D}_{KL}}({{S}_{s}},{{S}_{t}})\cdot {{T}^{2}}\]	
其中，${{S}_{s}}$和${{S}_{t}}$是两个网络的软化输出，$T$是用于调整分布的"软硬程度"温度参数，较高的温度$T$使分布更加平滑，有助于传递教师网络中的细微知识，而${{T}^{2}}$因子则用于平衡温度对损失梯度的影响。差异图注意力损失进一步整合了三个方面的知识传递：
	\[{{\mathcal{L}}_{att\_D}}=0.5{{\mathcal{L}}_{map}}+0.3{{\mathcal{L}}_{ch}}+0.2{{\mathcal{L}}_{sp}}\]	
这里，${{\mathcal{L}}_{map}}$关注差异图本身的一致性，${{\mathcal{L}}_{ch}}$和${{\mathcal{L}}_{sp}}$分别关注通道维度和空间维度的注意力一致性。权重分配反映了本研究对不同维度信息的重视程度，差异图是最基础的变化表示，因此获得最高权重；通道注意力次之，反映了"什么类型的特征"发生了变化；空间注意力权重最低，但仍然重要，表示"哪里"发生了变化。最终这三个层次的损失被整合为总体蒸馏损失：
	\[{{\mathcal{L}}_{D}}=0.3{{\mathcal{L}}_{feat}}+0.4{{\mathcal{L}}_{out}}+0.3{{\mathcal{L}}_{att\_D}}\]	
多层次蒸馏会同时将输出标签、中间表示、注意力分布纳入蒸馏的目标之内，有效地减小异源数据不同模态之间的差异性，从而使知识从教师网络能够传输给学生网络，并得到良好的知识迁移效果。设计时还充分考虑到了深层神经网络学习的本质，"表示学习"比分类器本身更重要。
3.3.差异图注意力迁移：变化感知的视觉向导
上文提到传统蒸馏方法只关注输出层面的一致性，忽略了中间表示的重要性，随后说明了GOLD模型为了突破这一局限构建了多层次蒸馏策略。本节将讲述如何构建一套完整的差异图生成与注意力迁移机制来为异源变化检测提供明确的视觉向导。
3.3.1.多度量差异图生成
差异图能够直观展现两时相图像间的异同，为此本文的GOLD模型融合了多种距离度量方法来捕捉异源数据中的复杂变化模式。首先计算特征在欧几里得空间中的L2距离，它反映了特征在数值上的绝对差异大小：
	\[{{D}_{L2}}=\sqrt{\sum{{{({{F}_{1}}-{{F}_{2}})}^{2}}}+\epsilon }\]	
其中${{F}_{1}}$和${{F}_{2}}$分别是两个时间点的特征，求和操作在特征维度上进行，$\epsilon $是一个很小的常数，用于数值稳定性。L2距离对特征值的变化非常敏感，能够捕捉数值上的细微差别。GOLD也计算特征向量间的余弦距离，它反映了特征方向的变化程度，不受特征幅值影响：
	\[{{D}_{cos}}=1-\frac{{{F}_{1}}\cdot {{F}_{2}}}{\|{{F}_{1}}\|\|{{F}_{2}}\|}\]	
这里的余弦距离关注的是特征向量的夹角，即使两个特征在幅值上差异很大，只要方向相似，余弦距离仍然较小，这对于处理异源数据尤为重要。最后将这两种距离进行简单平均，通过双曲正切函数进行非线性变换并调整值域得到最终的差异图：
	\[\begin{align}
  & {{D}_{comb}}=\frac{{{D}_{L2}}+{{D}_{cos}}}{2} \\ 
 & {{D}_{map}}=\tanh (2{{D}_{comb}})\cdot 0.5+0.5 \\ 
\end{align}\]	
对比传统的单一度量方法，GOLD模型的多度量融合策略既考虑了特征的绝对差异，又关注了特征的方向变化，能够有效应对异源数据的复杂变化模式。而且非线性变换不仅增强了差异对比度，还将值域标准化至0-1区间，便于后续的注意力计算。
3.3.2.双维度注意力设计
在差异图的基础上，GOLD 模型设计了空间和通道两个维度的注意力机制，实现了对变化区域的全方位感知。这两种注意力机制分别从"位置"和"特征"两个角度增强模型的变化感知能力。空间注意力关注的是"哪里"发生了变化，通过以下方式计算：
	\[{{A}_{sp}}=\sigma (Conv([Mean(F),Max(F)]))\]	
在这个公式中，首先沿通道维度计算特征图\[F\]的平均值和最大值，得到两个二维空间图，捕捉不同统计视角下的空间信息，然后将这两个图拼接，输入到一个卷积层中学习它们的组合方式，最后通过sigmoid函数$\sigma $将值域限制在0-1之间，形成像素级的注意力权重，就像在用"空间放大镜"来聚焦重要位置。通道注意力关注"什么类型的特征"发生了变化，计算方式为：
	\[{{A}_{ch}}=\sigma (FC(AvgPool(F))+FC(MaxPool(F)))\]	
这里分别对特征图$F$进行全局平均池化和最大池化，压缩空间维度，得到两个通道描述符，然后通过全连接层$FC$处理这些描述符来学习通道间的相互关系，最后同样通过sigmoid函数生成通道级的注意力权重。这种机制相当于给不同类型的特征赋予不同的重要性，就像在用"特征滤镜"来增强关键信息。
GOLD的双维度注意力设计克服了单一注意力机制的局限，空间注意力能够精确定位变化区域，提高模型的空间敏感性，通道注意力则强调变化相关的特征通道，增强模型的语义理解能力。二者协同工作，既知道"哪里"变了，又知道"变了什么"，为变化检测提供了多角度的感知能力。
3.3.3.教师指导的注意力迁移
GOLD模型的核心创新在于实现了从教师网络到学生网络的注意力迁移。这一过程可以形象地理解为"知识视线的同步"——教师网络告诉学生网络"应该看哪里"和"应该关注什么特征"。教师网络首先基于同源光学图像来计算差异图${{D}_{t}}$及其空间注意力$A_{sp}^{t}$和通道注意力$A_{ch}^{t}$，识别相对容易理解的光学-光学变化模式。同时学生网络基于异源光学-SAR图像计算相应的差异图${{D}_{s}}$和注意力表示$A_{sp}^{s}$、$A_{ch}^{s}$。GOLD通过以下损失函数引导学生网络模仿教师网络的"视线"：
	\[\begin{align}
  & {{\mathcal{L}}_{map}}=MSE({{D}_{s}},{{D}_{t}}) \\ 
 & {{\mathcal{L}}_{sp}}=MSE(A_{sp}^{s},A_{sp}^{t}) \\ 
 & {{\mathcal{L}}_{ch}}=MSE(A_{ch}^{s},A_{ch}^{t}) \\ 
\end{align}\]	
这些损失函数分别度量差异图本身、空间注意力和通道注意力的相似程度。通过最小化这些损失，学生网络逐渐学会像教师网络一样"看待"变化，即使面对的是异源数据。这就像一位经验丰富的遥感专家（教师网络）指导新手（学生网络）如何解读复杂的SAR图像："这里（空间注意力）的这种纹理变化（通道注意力）代表着建筑物发生了变化。"通过这种指导，新手逐渐掌握了识别变化的技巧，即使是面对抽象难懂的SAR图像。
本文的注意力迁移机制不仅增强了学生网络对变化区域的感知能力，还提供了变化检测的视觉可解释依据。当教师网络聚焦于某个区域时，学生网络也被引导关注相同区域，即使面对不同模态的输入数据。这有效缓解了模态差异带来的特征不一致问题，使学生网络能够避开噪声，提取有效的变化信号。
3.4.自适应动态权重：多任务学习的平衡
3.4.1.基于不确定性的权重学习
多任务学习面临的一个核心问题是：如何为各个任务分配合适的权重？传统方法往往依赖固定的权重系数，而GOLD模型借鉴不确定性理论，设计了更灵活的自适应权重学习机制，基本思想是任务的不确定性越高，其权重应当越低，反之，任务的不确定性越低，其权重应当越高。这样模型就能够更多地关注那些提供可靠学习信号的任务，减少不确定任务的干扰。具体实现上，首先让模型学习每个任务的不确定性参数$v$，然后基于这些参数计算初始权重$p$：
	\[p=softplus(-\log v)+\epsilon \]	
这里使用$softplus$函数确保权重为正值。这个转换实现了"不确定性高，权重低"的原则——不确定性$v$越大，$-\log v$越小，经过$softplus$后得到的权重$p$也越小。权重分配还考虑了训练的不同阶段。在热身阶段，本文设计了从固定权重到动态权重的平滑过渡：
	\[\begin{align}
  & \alpha =0.5(1-\cos (\tfrac{e}{{{e}_{w}}}\pi )) \\ 
 & w=(1-\alpha ){{w}_{f}}+\alpha \tfrac{p}{\sum{p}} \\ 
\end{align}\]	
其中，$e$是当前训练轮次，${{e}_{w}}$是热身阶段的总轮次，${{w}_{f}}$是预设的固定权重，$\alpha $是从0平滑增加到1的系数。这种设计确保了权重变化的连续性，避免了突变引起的训练不稳定。在后期训练时，本文还特别增强了主任务（变化检测）的权重，以保持其主导地位：
	\[\begin{align}
  & \lambda =\min (1.0+\tfrac{e-{{e}_{w}}}{100},1.5) \\ 
 & {{p}_{0}}=\lambda {{p}_{0}} \\ 
\end{align}\]	
这里，$\lambda $是随训练进程缓慢增加的主任务增强系数（1.5封顶），可使主任务一直得到足够关注，但又不过度压制其他任务。
这种动态权重的方法打破了原来多任务学习中固定的权重计算方法，可以依据学习情况自适应调节各任务之间的权重，使得整个多任务学习过程更为均衡。
3.4.2.类别不平衡的自适应处理
本文多次强调了变化检测任务通常面临严重的类别不平衡问题——变化区域往往仅占图像的小部分，因为这会使得模型容易倾向于预测"无变化"，忽略真正的变化区域。所以GOLD模型设计了基于变化比例的自适应权重调整策略，当图像中变化区域的比例${{r}_{c}}$小于预设阈值时，模型会按比例增加变化检测损失的权重：
	\[{{w}_{cd}}={{w}_{cd}}(1+5(0.1-{{r}_{c}}))\]	
这个公式体现了"稀有即重要"的思想，当变化区域仅占5%时，$0.1-{{r}_{c}}=0.05$，权重增幅为$5\times 0.05=0.25$，即增加了25%的权重，在变化区域超过10%后不再加权，模型不会因为某个区域的变化而权重大增，对于少量变化的地方多加关注；对于大片区域变化的地方，则会使权重变得更加平均一些，两部分的分量都会增加很多。就和做作业改错一样，比较少见的错误就多加反思，若都是比较普遍的错误就按照常理来纠错。
3.4.3.区域感知的动态权重迁移
上一节对全局层面的类别平衡问题（整体有多少变化），而本节关注的是局部层面的区域差异问题（变化发生在哪里）。变化检测任务不同区域的重要性并不相同——变化区域虽小但信息量大，非变化区域虽大但相对次要。基于这一认识，GOLD模型引入了区域感知的动态权重迁移机制，实现对不同区域的差异化处理。整个流程首先要基于教师网络提供的原始差异图${{D}_{o}}$构建动态调整因子：
	\[{{S}_{d}}=2({{D}_{o}}>1.3\overline{{{D}_{o}}})+0.5\]	
这里，$\overline{{{D}_{o}}}$是原始差异图的平均值，判别式$({{D}_{o}}>1.3\overline{{{D}_{o}}})$的作用是生成一个二值掩码用于标记那些差异显著高于平均水平的区域。当区域满足条件时，系数为2.5，表示重视这些显著变化区域，否则系数为0.5，相对降低非显著区域的权重。这种初步二值化处理只是第一步，接下来要对增强后的差异图$D={{D}_{o}}\cdot {{S}_{d}}$进行更精细的处理。为了实现更细致的权重分配，模型先将差异图$D$归一化到0-1范围内，并基于归一化差异图的统计特性自适应地设定阈值：
	\[\begin{align}
  & {{D}_{n}}=\frac{D-\min (D)}{\max (D)-\min (D)+\epsilon } \\ 
 & \theta =\overline{{{D}_{n}}}+\sigma ({{D}_{n}}) \\ 
\end{align}\]	
其中，$\overline{{{D}_{n}}}$是归一化差异图的均值，$\sigma ({{D}_{n}})$是其标准差。这个自适应阈值会随着差异图的分布特性自动调整，比固定阈值更加灵活。有了阈值后，模型根据阈值对差异图进行自适应增强或抑制：
	\[{{D}_{e}}=\left\{ \begin{array}{*{35}{l}}
   {{D}_{n}}\cdot \frac{{{D}_{n}}}{\theta }, & {{D}_{n}}>\theta   \\
   {{D}_{n}}\cdot \frac{{{D}_{n}}}{2\theta }, &   \\
\end{array} \right.\]	
这一步骤放大了高于阈值的变化区域（当${{D}_{n}}>\theta $时，乘以放大因子$\frac{{{D}_{n}}}{\theta }>1$），同时抑制了低于阈值的非变化区域（当${{D}_{n}}\le \theta $时，乘以衰减因子$\frac{{{D}_{n}}}{2\theta }<0.5$）。最后模型通过指数变换进一步增强对比度，并相对于平均值归一化，得到最终的权重掩码：
	\[{{M}_{w}}=\frac{\exp (2{{D}_{e}})}{\overline{\exp (2{{D}_{e}})}}\]	
这个$\overline{\exp (2{{D}_{e}})}$表示$\exp (2{{D}_{e}})$的平均值。指数函数能够指数级放大差异，而除以平均值则使掩码的整体均值接近1，便于后续的相对权重分析。有了权重掩码${{M}_{w}}$，GOLD现在就能将特征空间划分为变化区域和非变化区域：
	\[\begin{align}
  & {{R}_{c}}=({{M}_{w}}>1.5\overline{{{M}_{w}}}) \\ 
 & {{R}_{nc}}=1-{{R}_{c}} \\ 
\end{align}\]	
其中，$\overline{{{M}_{w}}}$是权重掩码的平均值，${{R}_{c}}$是变化区域的二值掩码，${{R}_{nc}}$是非变化区域的掩码。这种基于自适应阈值的区域划分方法能够根据每张图像的特点自动调整变化区域的范围。区域划分完成后，模型对不同区域应用不同强度的特征迁移损失：
	\[\begin{align}
  & {{\mathcal{L}}_{c}}=2\cdot MSE({{F}_{s}}\cdot {{R}_{c}},{{F}_{t}}\cdot {{R}_{c}}) \\ 
 & {{\mathcal{L}}_{nc}}=0.5\cdot MSE({{F}_{s}}\cdot {{R}_{nc}},{{F}_{t}}\cdot {{R}_{nc}}) \\ 
\end{align}\]	
这里，${{F}_{s}}$和${{F}_{t}}$分别是学生网络和教师网络的特征表示，${{\mathcal{L}}_{c}}$是变化区域的特征迁移损失，${{\mathcal{L}}_{nc}}$是非变化区域的特征迁移损失。变化区域的损失被赋予了更高的权重，而非变化区域的损失权重较低，这体现了本文对变化区域的高度重视。最终，GOLD模型将区域特定的损失函数与其他相关损失整合为一个综合的动态权重损失：
	\[{{\mathcal{L}}_{DW}}=0.5{{\mathcal{L}}_{f}}+0.3{{\mathcal{L}}_{a}}+0.2{{\mathcal{L}}_{d}}\]	
此处的${{\mathcal{L}}_{f}}$表示特征级损失（由变化区域损失${{\mathcal{L}}_{c}}$和非变化区域损失${{\mathcal{L}}_{nc}}$加权组成），确保学生网络在不同区域都能向教师网络学习，但对变化区域给予更高权重；${{\mathcal{L}}_{a}}$表示注意力机制损失（包括空间和通道注意力的迁移损失），确保学生网络能够像教师网络一样"看待"变化；${{\mathcal{L}}_{d}}$表示差异图损失，确保学生网络生成的差异图与教师网络相似。
GOLD模型的动态权重体现了深度学习中"关注重点"的思想，通过精细的区域划分和权重设计，实现了对变化区域的精准聚焦。
3.5.本章小结
GOLD模型的优点在于：
1.三分支师生架构引入事后的光学图像，成功构建了从同源到异源的知识传递桥梁，有效突破了传统双分支结构的局限性，不仅丰富了知识的流动路径，还提升了模型在处理复杂场景时的适应能力；
2.在线蒸馏机制实现了教师网络到学生网络的实时知识传递，使异源变化检测能够有效借鉴同源变化检测的宝贵经验，确保了学生网络能够动态学习，从而在异源图像数据下保持准确的变化检测性能；
3.差异图注意力迁移机制突出了关键差异区域，帮助模型更精准地定位和理解变化，为异源变化检测提供了清晰明确的视觉向导；
4.动态权重分配机制实现了多任务学习的自适应平衡，确保少数类别的变化不会被忽视，提升了模型在数据分布不均情况下的整体表现。
上述机制创新能够解决异源变化检测中存在的特征不一致性和类别不平衡的问题，而且GOLD模型在训练阶段虽然需要输入三个分支，但在推理阶段只需要输入学生网络的部分，保证了与普通变化检测模型一样的要求，极大提高了该模型的通用性，相较于其他目前常见的模型而言，GOLD模型是一种新颖的变化检测方案，为遥感图像跨模态学习提供了新思路。


第4章 数据获取与预处理
4.1.数据集获取
本研究使用的异源遥感图像数据集主要由高分二号（GF-2）光学图像、高分三号（GF-3）合成孔径雷达（SAR）图像和Sentinel-2光学图像组成。高分三号是中国首颗C波段多极化SAR卫星，具有全天时、全天候成像能力，分辨率可达1米，能提供全极化、多入射角等多种观测方式，适合用于灾害监测、资源调查和地形测绘等领域。高分二号是中国高分辨率光学遥感卫星，搭载两台PAN/MS相机，本研究使用其L1A级数据产品的多光谱数据MSS，运行于631公里太阳同步轨道，侧摆角度在±23°时重访周期为5天，是专为地理测绘、国土资源调查和精准农业等应用设计的图像集。Sentinel-2是欧空局哨兵计划的光学卫星系列，由Sentinel-2A和Sentinel-2B两颗卫星组成，相位差180度运行在同一轨道上，联合提供5天的重访周期，搭载多光谱成像仪MSI可采集13个光谱波段，其中4个波段为10米分辨率，6个波段为20米分辨率，3个波段为60米分辨率，轨道幅宽为290公里，本研究从哥白尼网站手动裁剪获取对应的图像集[36]。
研究区域涵盖了多个地区的城市化进程和建筑发展区域，选择这些区域作为研究对象，主要基于以下几个因素：
1.时间跨度适宜：所选区域在近几年正处于大规模的城市基础设施建设阶段，地表建筑物变化明显，利于变化检测模型的训练与评估。
2.高分辨率数据：本研究主要使用高分二号已处理好的4米分辨率图像；高分三号四极化条带I模式（QPSI, Quad Polarization Stripmap I）的原始图像，该模式入射角在20-41度之间，标称分辨率为8米，幅宽最大为25公里，可获取全极化数据（HH+HV+VH+VV）；Sentinel-2光学图像在可见光波段分辨率为10米，能够满足城市变化监测需求。
3.典型特征突出：选择的区域具有明显的城市化特征，包括建筑物密度增加、道路网络扩展和土地利用变化，这些特征是遥感变化检测中的典型研究对象。
4.2.数据预处理
异源遥感图像变化检测的一大难点就是由于图像来自不同传感器的原因导致两种图像间差别较大，要对二者进行变化检测，则必须先对其进行一定的预处理操作，使得这两者在空间上与辐射上的差距尽可能地小一些，进而为实现变化检测做准备。以下详细介绍针对GF-3 SAR图像的预处理流程，这些处理步骤是应用模型前的必要准备工作。


4.2.1.SAR图像导入与初始处理
表 4.1 高分三号数据集模式
序号	工作模式	入射角度	精度（米）	距离间距	方式
1	聚束（SL）	20～50	1	10	可选单极化
2	超精细条带（UFS）	20～50	3	30	可选单极化
3	精细条带1（FSI）	19～50	5	50	可选双极化
4	精细条带2（FSII）	19～50	10	100	可选双极化
5	标准条带（SS）	17～50	25	130	可选双极化
6	窄幅扫描（NSC）	17～50	50	300	可选双极化
7	宽幅扫描（WSC）	17～50	100	500	可选双极化
8	全球观测模式（GLO）	17～53	500	650	可选双极化
9	全极化条带1（QPSI）	20～41	8	30	全极化
10	全极化条带2（QPSII）	20～38	25	40	全极化
11	波模式（WAV）	20～41	10	5	全极化
12	低入射角	10～20	25	130	可选双极化
13	高入射角	50～60	25	80	可选双极化


图 4.1 原始数据导入（HH）
GF-3 SAR数据以L1B级产品形式提供，需要将其导入专业处理软件中进行预处理才能查看。上文提到，本研究使用的是GF-3卫星QPSI模式（四极化条带I模式）获取的全极化组合数据，提供了丰富的地表散射特性信息。本研究使用ENVI和SARscape组合进行SAR数据处理。系统在导入过程中读取图像的元数据信息xml文件，提取成像参数、轨道信息和坐标参考等关键信息。
导入后的SAR数据被转换为单视复数SLC格式，保留了幅度和相位信息。SLC数据的复数值表示为：
	\[{{S}_{SLC}}(i,j)=A(i,j){{e}^{j\phi (i,j)}}\]	
其中，$A(i,j)$表示幅度值，$\phi (i,j)$表示相位值，$(i,j)$为像素坐标。
4.2.2.多视处理
SAR图像由于其独特的成像机制，在方位向（飞行方向）通常具有较高的采样率，这使得方位向的分辨率明显优于距离向，导致图像在两个方向上的分辨率分布不均匀。这种不均匀性不仅影响图像的视觉呈现，还会在变化检测任务中增加处理难度。为此，多视处理（Multilooking）通过在方位向和距离向上对像素进行聚合，有效抑制由相干成像系统引发的斑点噪声，同时通过调整像素聚合比例，使地面投影的像素形状更接近正方形，从而改善图像的几何特性，提升其在实际应用中的适用性。
多视处理的核心参数是方位向多视数${{N}_{a}}$和距离向多视数${{N}_{r}}$，它们是根据原始像素间距和目标地面分辨率计算得出的：
	\[\begin{align}
  & {{N}_{r}}=\left\lceil \frac{{{R}_{g}}}{\Delta r} \right\rceil  \\ 
 & {{N}_{a}}=\left\lceil \frac{{{R}_{g}}}{\Delta a} \right\rceil  \\ 
\end{align}\]	
其中，${{R}_{g}}$是目标地面分辨率，$\Delta r$是距离向像素间距，$\Delta a$是方位向像素间距，$\left\lceil \cdot  \right\rceil $表示向上取整操作。距离向像素在地面上的投影与入射角$\theta $相关：
	\[{{R}_{g}}=\frac{\Delta r}{\sin (\theta )}\]	
多视处理后的SAR图像强度值通过对原始复数据的平均计算得到：
	\[{{I}_{ML}}({i}',{j}')=\frac{1}{{{N}_{r}}\times {{N}_{a}}}\sum\limits_{k=1}^{{{N}_{r}}}{\sum\limits_{l=1}^{{{N}_{a}}}{|}}{{S}_{SLC}}({{N}_{r}}\cdot {i}'+k,{{N}_{a}}\cdot {j}'+l){{|}^{2}}\]	
其中，$({i}',{j}')$是多视图像中的像素坐标，$|{{S}_{SLC}}{{|}^{2}}$表示SLC数据的强度（模的平方）。多视处理输出的是功率图像（Power Image），比原始的SLC数据具有更低的噪声水平和更均匀的空间分辨率。

图 4.2 多视处理（HH和VV）
4.2.3.斑点噪声滤波
SAR 图像的主要缺点之一是存在斑点噪声（Speckle Filtering），这种"颗粒状"是由相干辐射经过成像时随机干涉形成的，在雷达散射面造成粒子大小、大小不等，从而形成"颗粒状"，严重影响图像的解译和后期处理。
本文采用改进Lee滤波器（Refined Lee Filter）对图像降噪。由于此种降噪方法根据图像的局部区域统计信息来完成降噪，因此具有较强的边缘及线性特征保留能力，在消除噪声方面有着较好的效果，其滤波过程可用下式表示：
	\[{{I}_{filtered}}(i,j)={{I}_{mean}}(i,j)+K(i,j)\cdot [{{I}_{ML}}(i,j)-{{I}_{mean}}(i,j)]\]	
其中，${{I}_{mean}}(i,j)$是滑动窗口内的均值，$K(i,j)$是一个自适应权重系数，取决于窗口内的局部统计特性：
	\[K(i,j)=\frac{\sigma _{true}^{2}(i,j)}{\sigma _{ML}^{2}(i,j)}\]	
这里$\sigma _{true}^{2}(i,j)$是估计的无噪声图像方差，$\sigma _{ML}^{2}(i,j)$是观测到的多视图像方差。改进的Lee滤波器通过分析窗口内像素的方向特性，自适应地选择最适合的滤波子窗口，从而更好地保留线性特征和边缘。本研究使用了5×5像素的滑动窗口进行处理，该参数在保持细节和抑制噪声之间取得了良好平衡。

图 4.3 单通道强度数据滤波（HH和VV）
4.2.4.地理编码与辐射定标
精确的地形校正和地理编码需要高质量的数字高程模型（DEM）。本研究使用GMTED2010全球DEM数据来提取研究区域的高程信息，生成了与SAR图像匹配的局部DEM。DEM的网格大小设置为450米，因为这一分辨率足以反映研究区域的主要地形特征，而且处理效率也不低。DEM提取过程中使用了统一横轴墨卡托（UTM）投影，投影参数根据研究区域的中心经度自动计算得到：
	\[UT{{M}_{\text{zone}}}=\left\lfloor \frac{\text{longitude}}{6} \right\rfloor +31\]	
其中，$\left\lfloor \cdot  \right\rfloor $表示向下取整操作，\[longitude\]为区域中心经度（单位：度）。
地理编码是将SAR图像从斜距几何（Slant Range Geometry）转换到地面坐标系统的过程，直观的效果是能够校正地形引起的几何畸变。辐射定标则将SAR图像的灰度值转换为可量化的后向散射系数，使不同时间、不同成像条件下获取的图像具有可比性。地理编码的像素大小设置为8米，以匹配光学图像的分辨率，便于后续的异源变化检测。地理编码过程可表示为从斜距坐标$(r,a)$到地面坐标$(x,y,z)$的转换：
	\[(x,y,z)=F(r,a,\text{DEM})\]	
其中，$F$是一个复杂的函数，依赖于卫星轨道参数、成像几何和地形信息。辐射定标将SAR图像转换为标准的后向散射系数${{\sigma }^{0}}$：
	\[{{\sigma }^{0}}=\frac{\text{D}{{\text{N}}^{2}}\cdot \sin ({{\theta }_{loc}})}{K\cdot {{A}_{cell}}}\]	
其中，DN是原始像素值，${{\theta }_{loc}}$是局部入射角，K是定标常数，${{A}_{cell}}$是地面分辨单元面积。为了便于视觉解译和后续处理，后向散射系数通常转换为分贝单位：
	\[\sigma _{dB}^{0}=10\cdot {{\log }_{10}}({{\sigma }^{0}})\]	

图 4.4 匹配世界地图要求的图像（预处理步骤完成）
4.2.5.数据格式转换与最终输出
为了方便与光学数据融合以及提供给深度学习模型使用，经所有预处理后的SAR图像是需要进行格式转码的，转码后得到的是以标准格式存储的图，而且经过变换后的信息元数据文件（meta file）记录着有几波段、大小多少个像素，接下来再把这些东西转化成最后真正可以使用得到GeoTIFF格式，从而既保持了该图的地理参考信息，又能满足大多数图像处理软件以及深度学习框架的要求。最终输出的GF-3 SAR图像具有以下特点：
1.空间分辨率统一为8米
2.投影坐标系为UTM，基于WGS84椭球体
3.辐射值为分贝单位的后向散射系数
4.降低了斑点噪声，提高了图像质量
通过以上预处理步骤，SAR图像与光学图像达到了格式的一致性，为后续的异源变化检测模型训练和应用奠定了基础。
4.2.6.人工校正配准

图 4.5 人工选点配准校正
几何校正的目标是确保时间点1的高分二号光学图像、时间点2的高分三号SAR图像以及时间点2的Sentinel-2光学图像在空间位置上精确对齐，工作流程如下：
1.坐标系统统一：所有图像统一到WGS84坐标系下的UTM投影，确保投影带号一致。
2.控制点选取：人工在图像对中辨认道路交叉口、建筑物角点、水体边界等明显的地物特征作为对应的控制点GCPs。
3.几何变换模型：采用ENVI中的Fitting Global Transform几何模型和仿射变换进行几何校正。仿射变换保持了平行线的平行性，同时可以处理图像的平移、旋转、缩放和倾斜，变换方程可表示为：
	\[{x}'={{a}_{0}}+{{a}_{1}}x+{{a}_{2}}y\]	
	\[{y}'={{b}_{0}}+{{b}_{1}}x+{{b}_{2}}y\]	
其中，$(x,y)$是原始图像中的坐标，$({x}',{y}')$是校正后图像中的坐标，${{a}_{i}}$和${{b}_{i}}$是变换系数。为确保更高匹配精度的同时兼顾处理效率，采用了Forstner特征提取算法辅助识别匹配点，搜索窗口大小设置为128像素，匹配窗口大小为61像素。
4.重采样：使用适用于多源异质数据的双线性插值法（Bilinear Interpolation）对所有图像进行重采样。重采样像元大小统一设为8米，以平衡高分二号的高分辨率和Sentinel-2的中等分辨率。
5.精度评估：利用计算独立检验点RMSE来检验配准精度，研究配准后RMSE控制在3像素左右，在考虑异源数据的特性和研究区本身的复杂性情况下，这样的精度是可以满足变化检测需求的。
4.2.7.相对辐射归一化
相对辐射归一化（Relative Radiometric Normalization）是处理多时相图像时容易忽视的步骤，而本研究的图像由于来自不同传感器时，这一步必不可少。这项技术可以解决因大气条件不同、太阳角度不同、传感器参数不同以及成像条件的不同引起辐射不一致的问题，采取步骤为：
1.伪不变特征识别：找出研究区中伪不变特征（Pseudo-Invariant Features, PIFs），比如永久性建筑屋顶、大型停车场、机场跑道等地表覆盖类型与反射特性长时间未发生变化的地带，并以这种类型的PIFs为对象，通过比较PIFs在各时期的图像中的辐射量，得到相应图像间的辐射转换关系。
2.线性回归模型应用：根据时间点1高分二号光学图像作为参考图像（Reference Image），将时间点2的Sentinel-2光学图像作为待校正图像（Adjust Image）的共同区域内同名地物光谱特性进行分析比较，在此基础上求得二者相同区域的线性回归方程中所需要的增益（Gain）、偏置（Offset）参数：
	\[D{{N}_{norm}}=\alpha \cdot D{{N}_{orig}}+\beta \]	
其中，$D{{N}_{orig}}$是原始数字号，$D{{N}_{norm}}$是归一化后的数字号，增益$\alpha $和偏置$\beta $是针对每个波段自动计算的回归系数，考虑了不同卫星传感器的光谱响应差异，确保多源数据在辐射特性一致。
3.波段匹配处理：因为高分二号与Sentinel-2的波段设置不同，因此对于相对辐射归一化时必须对相应波段进行匹配；本文仅针对3个可见光波段（蓝、绿、红）实施归一化处理，尽管Sentinel-2具有13个波段，但是为了保证高分二号光学图像能取得较好的效果，采取与高分二号相同的方式选择对应的可见光波段，使不同传感器的光谱特性可比度更高。
经过相对辐射归一化后，时间点1的高分二号图谱和时间点2的Sentinel-2图谱在光谱特性上有较高的一致性，满足了基于光学图谱进行对比分析与变化检测的要求。
上面的几个步骤完成后，三个时相图中对应的空间位置以及辐射特征完全一致，为后期人工标注工作及异源变化检测算法提供质量较高的输入数据。

图 4.6 高分二号基准图像（左）、Sentinel-2辐射校正前（中）、Sentinel-2辐射校正后（右）
4.3.标注软件开发
4.3.1.开发背景
异源遥感图像变化检测主要瓶颈是高质量标注数据集的获取和标注，上文已经解决了数据集的获取，但是在标注方面现有遥感图像工具在处理异源数据时还存在明显不足：
1.因为无法有效处理异源数据的复杂性，所以传统标注工具是针对单源图像设计的，并不能够同时处理和对比光学图像、SAR图像等异源数据。不同传感器的成像原理、分辨率和光谱特性有明显的区别，人工标注起来比较困难且容易出错。
2.大多数现成工具都聚焦于基于单图像的语义分割和目标检测标注，而没有考虑到变化检测任务中涉及的两幅图像同步标注，缺少相应的专业标注信息来支持"变与不变"的标注要求。
3.纯手工标注的成本非常高，在对大量的高分辨率遥感图像进行人工标注的过程中十分耗费时间与人力。
4.3.2.技术基础
本研究在众多开源标注软件中选定Labelme[27]作为基础，并借鉴其复刻分支Labelme-CD[28]的双图标注功能，主要基于以下两方面考虑：第一，LabelMe基于Python与Qt,支持多边形、矩形、圆形以及AI多边形等多种标注，界面友好，交互顺滑，但仅支持一张图的单独标注；第二，LabelMe-CD虽然沿用了LabelMe的核心结构并增加了面向变化检测的双图对齐和标注流程，但还没有添加AI辅助标注模块，并且版本较老，不太方便使用。基于LabelMe成熟的底层开发平台和LabelMe-CD专注于异源遥感双图标注的优势，本文选择基于LabelMe进行程序二次开发，在保证系统稳定性的基础上针对变化检测的应用场景编写软件。
4.3.3.核心功能

图 4.7 LabelmeCD-AI界面展示
系统界面左右分屏，分别呈现时间点1和时间点2的遥感图像，用户在任一视图上执行缩放或平移操作时，另一视图将自动同步至相同地理范围，以保证两幅图像的始终对齐。用户标注的时候在一幅图像上绘制的多边形或矩形会实时映射到另一幅图像，便于对应区域的比对；通过快捷键或工具栏按钮即可在左右视图间快速切换焦点，支持对单点或小范围区域的细致复核。
平台集成了OSAM（Open Segment Anything Model）目标分割模块，能够自动判别如建筑物、道路等重要地物并输出分割轮廓，可以在界面上人工增加或者减少、合并或者细化AI建议输出的内容，保证了标注的精度同时极大地提升了效率。
在处理GeoTIFF文件时，其内部嵌入的坐标参考系以及图像投影信息是确保空间数据准确性的关键组成部分。这些信息通常存储在文件的元数据中，包括地理坐标系、投影类型以及基准面等，用于在分析软件中精确定位和分析影像数据。本工具在设计时充分考虑了这些空间参考信息的完整性，所有操作均不对原始GeoTIFF文件的元数据和图像内容造成任何修改或破坏，确保处理后的GeoTIFF文件能够无缝导入GIS等其他分析软件，保持其空间参考的准确性，从而支持后续的地图叠加、空间分析或可视化任务。这种非破坏性的处理方式保证了用户在进行SAR图像优化时，既能提升图像质量，又不会影响其在专业应用中的地理定位能力。
软件自带完整的标注质量检查模块，可以自动检测未闭合多边形、重叠区域、漏标区域；导出时也支持将标注文件导出成Labelme标准JSON格式及二值掩码PNG格式，可以直接被用于变化检测算法训练中使用或接入到常见的深度学习框架中使用。
4.3.4.软件模块
LabelmeCD-AI采用模块化设计架构，主要包括以下几个核心模块：
表 4.2 软件核心模块表
模块名称	描述
用户界面模块	负责图像显示、标注交互、用户操作处理和快捷键管理。
图像处理模块	处理遥感图像的加载、预处理、格式转换功能。
AI辅助模块	集成深度学习模型，提供智能标注建议。
数据管理模块	负责标注数据的存储、管理、导出和统计分析。
插件管理模块	支持功能扩展，便于集成新的算法和工具。
4.4.本章小结
本章详细阐述了基于全监督学习的异源遥感图像变化检测研究中的数据获取与预处理过程，涵盖数据集获取、数据预处理、标注软件开发以及标注后处理四个核心部分。
对于数据集获取来说，本研究选用的是高分二号光学图像、高分三号SAR图像和Sentinel-2光学图像作为数据源。根据以上分析所提到的条件来确定选择什么样的数据集，一是选择时间跨度够大的，二是图像能够反映出明显的地表变化、图像的清晰度要高并且图像中有建筑物增多等体现城市化的典型特征，因为这些特性都是模型需要学习的典型样本。
数据预处理包括了对GF-3 SAR图像的导入与初始处理、多视处理、斑点噪声滤波、DEM提取与应用、地理编码与辐射定标、数据格式转换与输出，在消除了部分斑点噪声后将所有的图像空间分辨率调整到8m,并分别获取了时间点1 GF-2光学图像、时间点2GF-3 SAR图像及Sentinel-2光学图像，经过人工校正配准和相对辐射归一化得到了符合一致性的多时相的GF-2光学图像、GF-3SAR图像和Sentinel-2光学图像数据集。
为应对异源遥感图像标注的复杂性，本研究根据Labelme和Labelme-CD各自特点，开发了LabelmeCD-AI标注软件，集成了双图像同步显示与标注、AI辅助标注、遥感专用数据格式支持等功能。
综上，本章通过系统化的数据获取与预处理流程，为异源遥感图像变化检测研究提供了全面高质量的数据支持，为后续模型的设计与优化创造了条件。


第5章 实验与结果分析
5.1.实验设置
5.1.1.超参数设置
表 5.1 基本训练参数
参数名称	值	说明
批次大小	8	训练时的批量大小
初始学习率	0.0005	训练起始学习率
优化器	AdamW	训练时加速收敛
学习率策略	余弦退火	随训练进度平滑降低学习率
训练轮次	400	总训练轮次
初始化类型	normal	权重初始化方法，增益系数0.02

表 5.2 蒸馏与注意力参数
参数名称	值	说明
蒸馏温度	2	软标签平滑参数
特征蒸馏权重	0.3	控制特征级蒸馏损失贡献
输出蒸馏权重	0.4	控制输出级蒸馏损失贡献
差异图注意力权重	0.3	控制差异图注意力损失贡献
差异图权重	0.5	差异图损失在注意力损失中的权重
通道注意力权重	0.3	通道注意力在注意力损失中的权重
空间注意力权重	0.2	空间注意力在注意力损失中的权重
差异图缩放因子	10	差异图注意力总损失的缩放系数

表 5.3 动态权重与高级优化参数
参数名称	值	说明
热身轮次	20	权重从固定过渡到动态的轮次数
梯度裁剪范数	1	防止梯度爆炸的裁剪阈值
梯度累积步数	1	支持大批次训练的梯度累积机制
双向注意力机制	开启	增强模态间信息流动
对比学习损失	开启	权重10.0，温度参数0.5

5.1.2.训练优化策略
在深度学习模型的训练过程中，优化器的选择和学习率的调整对于模型的训练效果和收敛速度具有重要影响。本研究采用AdamW优化器进行参数更新：
	\[{{\theta }_{t+1}}={{\theta }_{t}}-\eta \cdot \frac{{{{\hat{m}}}_{t}}}{\sqrt{{{{\hat{v}}}_{t}}}+\epsilon }-\eta \cdot \lambda \cdot {{\theta }_{t}}\]	
其中学习率$\eta =0.0005$，权重衰减系数$\lambda =0.01$。模型首先在已有的ResNet-18预训练权重基础上，采用cosine学习率衰减策略，确保训练过程中学习率平滑下降：
	\[{{\eta }_{t}}={{\eta }_{min}}+\frac{1}{2}({{\eta }_{max}}-{{\eta }_{min}})(1+\cos (\frac{{{t}_{current}}}{{{t}_{total}}}\pi ))\]	
除此之外还有许多训练优化策略。多GPU并行通过将训练任务分配到多个GPU上加速模型训练，大大减少了计算时间。数据预加载利用多线程技术提前加载数据，避免数据因等待而产生卡顿。断点续训功能允许保存训练状态，并在需要时从保存点继续训练，保证了训练的连续性和稳定性，在爆显存等训练意外中断的情况下能够恢复进度。梯度累积通过设置步长累积梯度，优化了内存使用，在显存有限的情况下也能具备大批量效果。
5.2.数据集说明
对预处理完成的遥感图像使用个人开发的LabelmeCD-AI进行标注。标注完成的数据共有24组，每组包括时间点1的光学图像A、时间点2的SAR图像B、时间点2的光学图像C以及变化标签Label。为了匹配GOLD网络结构，分块大小为512×512像素、裁剪重叠比例为50%、尺寸容差为2像素，最终从24组原始图像中生成了2370组512×512像素的小块，并通过质量检查剔除了208组平均像素值低于5.0的"全黑"图像，最终保留2162组有效图像小块。
为了避免训练集和验证集之间的数据泄露，将这些重叠的图像小块进行分组，24个原始图像总共分为1068组相互不重叠的图像，并计算每个图像组的变化区域比例（即标签图像中白色像素的占比）。在划分数据集时，遵循"同一原始图像的不同区域同时出现在训练集和验证集"的原则，最终训练集分配到1740组图像，平均变化区域比例为6.54%，占总数的80.5%；验证集分配到422组图像，平均变化区域比例为6.36%，包含395张图像，占总数的19.5%。训练时对数据集除了翻转和旋转以外，还有随机裁剪与缩放、高斯模糊和颜色抖动的增强方法。
表 5.4 最终数据集情况
数据集	小块数	占总数百分比	平均变化区域比例
训练集	1740	80.50%	6.54%
验证集	422	19.50%	6.36%

该数据集分配方法解决了异源遥感图像处理中尺寸不一致、数据质量参差不齐以及数据集划分不当导致信息泄露问题，为后续模型训练提供了结构合理、分布均衡的高质量数据集。各子集中的A、B、C和Label图像文件名完全匹配，保持一一对应关系。

图 5.1 A（左上）、B（右上）、C（左下）、Label（右下）
5.3.结果对比
为了全面评估所提GOLD模型在异源遥感图像变化检测任务中的优势，本节选取了几种在文献中广泛应用的最先进模型，并对这些模型与GOLD学生网络在自建数据集和同一评价指标体系下的表现进行比较。接下来将介绍各对比模型：
1.FC-EF是最常见的全卷积网络孪生模型，使用变化检测的启发式方法[37]。
2.LightCDNet是专为工业应用和边缘设备设计的轻量级变化检测网络，由融合骨干网络和金字塔解码器组成，核心组件是深度监督融合模块，可引导主要特征的早期融合以提高性能，在保持高精度的同时，减小了模型体积，适合资源受限环境[38]。
3.TinyCD是使用孪生U-Net架构的轻量级变化检测模型，以全局时间和局部空间的方式利用低级特征，采用新策略在时空域中混合特征，并结合了MLP块形成了空间-语义注意力机制——混合与注意力掩码块，在极小的模型体积下实现了出色的变化检测性能[39]。
4.BIT是利用Transformer进行遥感图像变化检测的模型，通过将双时态图像表示为语义标记，在紧凑的基于标记的时空中建模上下文来捕捉长距离概念关系，比起纯卷积基线来说仅使用三倍以下的计算成本和模型参数[40]。
5.SNUNet-ECAM是密集连接孪生网络和U-Net的组合，通过编码器和解码器之间以及解码器和解码器之间的紧密信息传输，减轻了深层网络中定位信息的丢失，还引入了集成通道注意力模块用于深度监督，能够提炼不同语义层次的代表性特征，在精度和计算量之间取得了良好平衡[41]。
6.ChangeFormer是更出色的基于Transformer架构的孪生网络架构，它统一了具有层次结构的Transformer编码器和多层感知器解码器，能够高效地呈现准确变化检测所需的多尺度长距离细节，在处理复杂场景变化时表现出色[42]。
表 5.5 实验结果对比
模型	IoU	F1	准确率	召回率
FC_EF	66.95	76.63	84.94	71.83
LightCDNet	67.17	76.84	85.52	71.90
TinyCD	75.32	84.22	89.31	80.44
BIT	77.25	85.87	83.16	89.18
SNUNet_ECAM	79.93	87.13	90.44	84.05
ChangeFormer	80.21	86.97	89.98	84.16
GOLD（学生）	85.98	92.02	90.94	93.16
GOLD（教师）（同源数据）	86.61	92.42	90.70	94.34

实验结果表明，本文提出的GOLD模型在异源遥感图像变化检测任务中表现优异。在遥感图像变化检测任务中，IoU是最能直接反映变化区域重叠程度的关键指标，GOLD学生网络在异源数据上取得了85.98%的IoU，远高于其他对比方法。
尽管处理更具挑战性的异源数据，基于在线知识蒸馏的GOLD学生网络性能几乎可以媲美用于同源数据的教师网络（IoU 85.98% vs 86.61%），仅有0.63%的差距，充分证明了本文提出的在线知识蒸馏方法的强大有效性。通过本文创新设计的差异图注意力迁移机制和动态权重分配策略，教师网络能够在训练过程中实时将同源数据处理的知识高效迁移到学生网络，使学生网络能够有效应对异源数据中的模态差异和特征不一致性问题。
相比之下，其他模型各有不足。最先进的ChangeFormer的IoU为80.21%，与本文的GOLD学生网络相差近6个百分点。SNUNet_ECAM虽然表现也不错，IoU达到79.93%，但仍与本研究的模型有明显差距。BIT在召回率上表现较好（89.18%），但整体IoU仅为77.25%。至于性能更弱的FC_EF和LightCDNet的IoU分别为66.95%和67.17%，在复杂场景中的变化检测能力远不及GOLD模型。
GOLD模型的卓越性能主要得益于在线知识蒸馏机制，与传统的预训练-微调或离线蒸馏不同，在线蒸馏方法允许教师网络和学生网络同时训练，实现了知识的实时传递。差异图注意力迁移机制让GOLD的教师网络将同源数据提取的高质量变化特征直接用于指导学生网络，帮助学生网络在异源数据上精准定位变化区域。这种创新的学习方式不仅大幅提升了模型在异源遥感变化检测任务中的性能，而且为解决遥感领域中普遍存在的数据异质性问题提供了新的思路。
5.4.消融实验
表 5.6 不同组件对模型性能的影响
模型配置	IoU	F1	准确率	召回率
基础模型（Baseline）	78.21	86.74	88.32	83.65
+三分支在线蒸馏	83.12	90.34	89.21	90.23
+差异图注意力迁移	84.21	90.83	89.58	91.14
+动态权重分配（完整模型）	85.98	92.02	90.94	93.16
-轻量化模型	82.84	89.55	87.59	90.79

为了全面评估所提出方法中各组件的有效性，本研究进行了一系列消融实验。从研究过程和实验结果可以看出，三分支在线蒸馏策略带来了显著的性能提升，准确率从88.32%提高到89.21%，召回率更是从83.65%大幅提升至90.23%，IoU指标从78.21%提高到83.12%，增加了约4.91个百分点。这证明了在处理异源遥感图像变化检测任务时，利用教师网络（光学-光学分支）通过知识蒸馏的方式指导学生网络（光学-SAR分支）的学习过程是非常有效的。
引入差异图注意力迁移机制后，模型准确率提高到89.58%，召回率达到91.14%，IoU达到84.21%，较仅使用蒸馏的模型又提高了约1.09个百分点。这表明差异图注意力迁移通过关注图像变化区域的关键特征，增强了模型对变化区域的感知能力，减少了假阳性和假阴性检测。
最后动态权重分配机制的加入使完整模型的性能达到最优，准确率提高到90.94%，召回率达到93.16%，F1值达到92.02%，IoU指标提高到85.98%，较前一阶段又增加了约1.77个百分点。动态权重分配根据训练过程中不同损失项的重要性自适应调整其权重，平衡了变化检测损失、蒸馏损失和差异图注意力损失的贡献，避免了单一损失项主导训练过程，从而使模型能够更全面地学习异源图像中的变化特征。
表 5.7 GOLD完整模型和轻量化模型GPU资源使用对比
模型类型	参数量（M）	显存占用（MB）	PyTorch分配显存（MB）	GPU耗能率（%）
完整模型	37.254	6319.8	3513.54	20
轻量化模型	9.401	2571.8	43.27	3.8

本研究还探索了模型复杂度与性能的权衡，设计了一个轻量化版本的模型。相比于完整模型37.254M参数量，轻量化模型通过一系列核心策略大幅减少计算复杂度，9.401M的参数量就能保持较高性能。在骨干网络方面，将主要卷积层的通道数减少50%（从128降至64），部分3×3卷积替换为1×1卷积以减少参数量，并减少部分残差连接；注意力模块方面，缩减比率从16增加到32，简化MLP层结构并减少中间通道数；在特征融合优化上，将部分特征拼接操作替换为计算量更小的加权求和操作，减少特征融合前的转换层通道数；蒸馏过程也进行了精简，选择性地仅传递关键层特征信息进行蒸馏，优化蒸馏温度参数以提高知识传递效率，简化教师网络结构的同时保持关键特征表示能力。轻量化模型虽然准确率降至87.59%，但在保持接近完整模型性能的同时（IoU从85.98%降至82.84%），参数量减少约74.77%，带来了显著的显卡资源节约。完整模型在推理过程中平均占用6319.80MB显存，而轻量化模型仅需2571.80MB显存，显存占用降低了约59.30%。PyTorch实际分配显存的对比更为显著：完整模型平均需要3513.54MB，轻量化模型仅需43.27MB。GPU耗能率（利用率）方面，完整模型平均为20.00%，轻量化模型仅为3.80%。这些数据充分证明了轻量化策略在保持模型性能的同时，大幅降低了计算资源需求，为边缘计算设备和资源受限场景下的部署提供了可行方案。

图 5.2 完整模型（左）、真实标签（中）、轻量化模型（右）
5.5.本章小结
在本章中针对GOLD模型进行了一系列试验，用以全面检验GOLD模型对于异源遥感图像变化检测的效果以及各个创新点的有效性，并从4个方面对模型效果进行论证。
实验部分说明了超参数的设置，保证了模型训练中的超参数配置正确和过程稳定可复现，并且使用了各种优化手段，包括使用先进优化器、合理调节学习率以及通过多GPU并行、数据预加载提高训练效率、加快收敛速度。
数据集说明显示了如何进行高质量数据集的后期处理工作，使数据集有良好的质量与分布情况，保证后续进行模型训练与评估可以建立可靠的依据。
在结果对比部分，本文将GOLD模型与多种先进的变化检测模型进行了性能比较。实验表明GOLD模型在关键指标上表现出色，能够更全面地检测变化区域，减少漏检现象。
消融实验通过逐个增加不同的组件，分析了各个组件给模型带来的影响。三分支在线蒸馏、差异图注意力迁移、动态权重分配等三个组件均能够有效提升模型效果，这几个组件通过消除异源数据的模态差异、增大变化区域感知、平衡训练过程中的损失项，使得模型效果提升。另外也分析了轻量级模型，能够在保证效果的基础上降低模型计算复杂度，为一些硬件受限环境提供一种有效的方案。